server:
  port: 8080
  servlet:
    context-path: /api

app:
  host: shiguang
  server:
    host: shiguang

spring:
  datasource:
    url: jdbc:mysql://${app.host}:3306/agri_big_data?createDatabaseIfNotExist=true&useUnicode=true&characterEncoding=utf8&useSSL=false&allowPublicKeyRetrieval=true
    username: root
    password: 082415
    driver-class-name: com.mysql.cj.jdbc.Driver
  jpa:
    hibernate:
      ddl-auto: update
    show-sql: true
    properties:
      hibernate:
        dialect: org.hibernate.dialect.MySQL8Dialect
        format_sql: true
  servlet:
    multipart:
      max-file-size: 100MB
      max-request-size: 100MB
  main:
    allow-circular-references: true
    allow-bean-definition-overriding: true
  web:
    cors:
      allowed-origins: "*"
      allowed-methods: GET,POST,PUT,DELETE,OPTIONS
      allowed-headers: "*"
      allow-credentials: true
      max-age: 3600

hadoop:
  hdfs:
    block:
      size: 67108864
    replication: 3
    use:
      datanode:
        hostname: false
    buffer:
      size: 4096
    uri: hdfs://${app.host}:9000
    user: root
    root-dir: /user/hadoop
    connection:
      required=false: false
      required: false
    impl: org.apache.hadoop.hdfs.DistributedFileSystem

hive:
  jdbc:
    url: jdbc:hive2://${app.host}:10000/default
    driver: org.apache.hive.jdbc.HiveDriver
    username: root
    password: 
  url: jdbc:hive2://${app.host}:10000
  username: root
  password:
  database: default
  driver: org.apache.hive.jdbc.HiveDriver
  connection:
    timeout: 30
    required: false


# JWT配置
security:
  jwt:
    token:
      secret-key: MzK4xNjQ5MDIzODckMTY0OTAyMzg3Jib20kMTYNDkwMjM4JiYzJDE2NDkwMjM4a27nczNzJiJjb20kMTY0OTAyMzg3QHNzY2jYW4
      expire-length: 86400000 # 24小时，单位：毫秒

debug: false

# Spark 配置
spark:
  app:
    name: HadoopSparkApp
  master: yarn
  executor:
    memory: 1g
  driver:
    memory: 1g

# Kafka 配置
kafka:
  bootstrap:
    servers: ${app.host}:9092
  consumer:
    group:
      id: hadoop-consumer-group
  host: ${app.host}
  port: 9092
