server:
  port: 8000
  servlet:
    context-path: /api

# 基础配置，可根据环境自动切换
app:
  # 默认主机名，将被特定环境配置覆盖
  host: shiguang
  server:
    host: shiguang

spring:
  application:
    name: hadoop2-kafka-ws
  datasource:
    # 数据库连接使用统一的app.host变量
    url: jdbc:mysql://${app.host}:3306/agri_big_data?createDatabaseIfNotExist=true&useUnicode=true&characterEncoding=utf8&useSSL=false&allowPublicKeyRetrieval=true
    username: root
    password: 082415
    driver-class-name: com.mysql.cj.jdbc.Driver
  jpa:
    hibernate:
      ddl-auto: update
    show-sql: true
    properties:
      hibernate:
        dialect: org.hibernate.dialect.MySQL8Dialect
        format_sql: true
  servlet:
    multipart:
      max-file-size: 100MB
      max-request-size: 100MB
  main:
    allow-circular-references: true
    allow-bean-definition-overriding: true
  web:
    cors:
      allowed-origins: "*"
      allowed-methods: GET,POST,PUT,DELETE,OPTIONS
      allowed-headers: "*"
      allow-credentials: true
      max-age: 3600
  websocket:
    enabled: true
    endpoint: /api/ws
    allowed-origins: "*"
    max-text-message-size: 8192
    max-binary-message-size: 8192


# Hadoop配置
hadoop:
  hdfs:
    uri: hdfs://${app.host}:9000
    user: root
    connection:
      required: false

# Hive配置
hive:
  url: jdbc:hive2://${app.host}:10000
  username: root
  password:
  driver: org.apache.hive.jdbc.HiveDriver

# JWT配置
security:
  jwt:
    token:
      secret-key: MzK4xNjQ5MDIzODckMTY0OTAyMzg3Jib20kMTYNDkwMjM4JiYzJDE2NDkwMjM4a27nczNzJiJjb20kMTY0OTAyMzg3QHNzY2jYW4
      expire-length: 86400000 # 24小时，单位：毫秒

# Spark 配置
spark:
  master: local[*]

# Kafka 配置
kafka:
  bootstrap:
    # 根据环境配置，可以在环境特定文件中覆盖
    servers: ${app.host}:9092

# 阿里云OSS配置
aliyun:
  oss:
    endpoint: oss-cn-hangzhou.aliyuncs.com
    accessKeyId: LTAI5tGdSLhRi6vV8NZSiwxf
    accessKeySecret: sXTN21tXw5uWPwULy9ffVMjz51IeGl
    bucketName: shiguang123418
    urlPrefix: https://shiguang123418.oss-cn-hangzhou.aliyuncs.com/